<div align="center">
  <h1>DIVE into MoE</h1>
  <div>
    <a href="#overview">📝 Overview</a> | <a href="#installation">⚙️ Installation Guide</a> | <a href="#quick-start">🚀 Quick Start</a> | <a href="#method">🚅 Method Details</a> | <a href="#evaluation">💎 Evaluation</a>
  </div>
</div>


<h2 id="todo">📦 To be released</h2>

<h2 id="overview">📝 Overview</h2>

This repository contains the official implementation of our ACL 2025 paper "DIVE into MoE: Diversity-Enhanced Reconstruction of Large Language Models from Dense into Mixture-of-Experts".

<h2 id="installation">⚙️ Installation</h2>

<h2 id="quick-start">🚀 Quick Start</h2>

<h2 id="method">🚅 Method Details</h2>

<h2 id="evaluation">💎 Evaluation</h2>

<h2 id="citation">💬 Citation</h2>