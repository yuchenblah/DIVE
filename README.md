<div align="center">
  <h1>DIVE into MoE</h1>
  <div>
    <a href="#overview">ğŸ“ Overview</a> | <a href="#installation">âš™ï¸ Installation Guide</a> | <a href="#quick-start">ğŸš€ Quick Start</a> | <a href="#method">ğŸš… Method Details</a> | <a href="#evaluation">ğŸ’ Evaluation</a>
  </div>
</div>


<h2 id="todo">ğŸ“¦ To be released</h2>

<h2 id="overview">ğŸ“ Overview</h2>

This repository contains the official implementation of our ACL 2025 paper "DIVE into MoE: Diversity-Enhanced Reconstruction of Large Language Models from Dense into Mixture-of-Experts".

<h2 id="installation">âš™ï¸ Installation</h2>

<h2 id="quick-start">ğŸš€ Quick Start</h2>

<h2 id="method">ğŸš… Method Details</h2>

<h2 id="evaluation">ğŸ’ Evaluation</h2>

<h2 id="citation">ğŸ’¬ Citation</h2>